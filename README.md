### Project Overview
In this project, various important methods of Numerical Methods have been implemented and presented in a topic-wise manner. The project is divided into major sections including Solution of Linear Equations, Non-Linear Equations, Differential Equation Solving, Interpolation Methods, Numerical Differentiation, Curve Fitting/Regression, and Numerical Integration. Each method under every section is organized separately into Theory, C++ Code, Input, and Output parts. The overall structure and topic-wise organization of the project are clearly documented in the README.md file, making the work easy to understand and follow. This project serves as a well-organized and user-friendly reference for learning numerical methods. 
---

# Table of Contents

- [Solution of Linear Equations](#solution-of-linear-equations)
  - [Gauss Elimination Method](#gauss-elimination-method)
    - [Theory](#gauss-elimination-theory)
    - [Code](#gauss-elimination-code)
    - [Input](#gauss-elimination-input)
    - [Output](#gauss-elimination-output)
  - [Gauss Jordan Elimination Method](#gauss-jordan-elimination-method)
    - [Theory](#gauss-jordan-theory)
    - [Code](#gauss-jordan-code)
    - [Input](#gauss-jordan-input)
    - [Output](#gauss-jordan-output)
  - [LU Decomposition Method](#lu-decomposition-method)
    - [Theory](#lu-decomposition-theory)
    - [Code](#lu-decomposition-code)
    - [Input](#lu-decomposition-input)
    - [Output](#lu-decomposition-output)
  - [Matrix Inversion](#matrix-inversion)
    - [Theory](#matrix-inversion-theory)
    - [Code](#matrix-inversion-code)
    - [Input](#matrix-inversion-input)
    - [Output](#matrix-inversion-output)
      
- [Solution of Non-Linear Equations](#solution-of-non-linear-equations)
  - [Bisection Method](#bisection-method)
    - [Theory](#bisection-theory)
    - [Code](#bisection-code)
    - [Input](#bisection-input)
    - [Output](#bisection-output)
  - [False Position Method](#false-position-method)
    - [Theory](#false-position-theory)
    - [Code](#false-position-code)
    - [Input](#false-position-input)
    - [Output](#false-position-output)
  - [Newton Raphson Method](#newton-raphson-method)
    - [Theory](#newton-raphson-theory)
    - [Code](#newton-raphson-code)
    - [Input](#newton-raphson-input)
    - [Output](#newton-raphson-output)
  - [Secant Method](#secant-method)
    - [Theory](#secant-theory)
    - [Code](#secant-code)
    - [Input](#secant-input)
    - [Output](#secant-output)

- [Differential Equation Solving](#differential-equation-solving)
  - [Runge-Kutta 4th Order Method](#runge-kutta-4th-order-method)
    - [Theory](#runge-kutta-theory)
    - [Code](#runge-kutta-code)
    - [Input](#runge-kutta-input)
    - [Output](#runge-kutta-output)

- [Interpolation Methods](#interpolation-methods)
  - [Newton Forward Interpolation](#newton-forward-interpolation)
    - [Theory](#newton-forward-theory)
    - [Code](#newton-forward-code)
    - [Input](#newton-forward-input)
    - [Output](#newton-forward-output)
  - [Newton Backward Interpolation](#newton-backward-interpolation)
    - [Theory](#newton-backward-theory)
    - [Code](#newton-backward-code)
    - [Input](#newton-backward-input)
    - [Output](#newton-backward-output)
  - [Newton Divided Difference Interpolation](#newton-divided-difference-interpolation)
    - [Theory](#newton-divided-difference-theory)
    - [Code](#newton-divided-difference-code)
    - [Input](#newton-divided-difference-input)
    - [Output](#newton-divided-difference-output)

- [Numerical Differentiation](#numerical-differentiation)
  - [Differentiation by Forward Interpolation](#differentiation-by-forward-interpolation)
    - [Theory](#differentiation-forward-theory)
    - [Code](#differentiation-forward-code)
    - [Input](#differentiation-forward-input)
    - [Output](#differentiation-forward-output)
  - [Differentiation by Backward Interpolation](#differentiation-by-backward-interpolation)
    - [Theory](#differentiation-backward-theory)
    - [Code](#differentiation-backward-code)
    - [Input](#differentiation-backward-input)
    - [Output](#differentiation-backward-output)

- [Curve Fitting / Regression](#curve-fitting--regression)
  - [Linear Regression](#linear-regression)
    - [Theory](#linear-regression-theory)
    - [Code](#linear-regression-code)
    - [Input](#linear-regression-input)
    - [Output](#linear-regression-output)
  - [Polynomial Regression](#polynomial-regression)
    - [Theory](#polynomial-regression-theory)
    - [Code](#polynomial-regression-code)
    - [Input](#polynomial-regression-input)
    - [Output](#polynomial-regression-output)
  - [Transcendental Regression](#transcendental-regression)
    - [Theory](#transcendental-regression-theory)
    - [Code](#transcendental-regression-code)
    - [Input](#transcendental-regression-input)
    - [Output](#transcendental-regression-output)

- [Numerical Integration](#numerical-integration)
  - [Simpson's 1/3 Rule](#simpsons-13-rule)
    - [Theory](#simpson-13-theory)
    - [Code](#simpson-13-code)
    - [Input](#simpson-13-input)
    - [Output](#simpson-13-output)
  - [Simpson's 3/8 Rule](#simpsons-38-rule)
    - [Theory](#simpson-38-theory)
    - [Code](#simpson-38-code)
    - [Input](#simpson-38-input)
    - [Output](#simpson-38-output)

---

# Numerical Methods

---


## Solution of Linear Equations

---

### Gauss Elimination Method

#### Gauss Elimination Theory

[Add your theory content here]

#### Gauss Elimination Code

```python
# Add your code here
```

#### Gauss Elimination Input

```
[Add your input format here]
```

#### Gauss Elimination Output

```
[Add your output format here]
```

---

### Gauss Jordan Elimination Method

#### Gauss Jordan Theory

[Add your theory content here]

#### Gauss Jordan Code

```python
# Add your code here
```

#### Gauss Jordan Input

```
[Add your input format here]
```

#### Gauss Jordan Output

```
[Add your output format here]
```

---

### LU Decomposition Method

#### LU Decomposition Theory

[Add your theory content here]

#### LU Decomposition Code

```python
# Add your code here
```

#### LU Decomposition Input

```
[Add your input format here]
```

#### LU Decomposition Output

```
[Add your output format here]
```

---

### Matrix Inversion

#### Matrix Inversion Theory

[Add your theory content here]

#### Matrix Inversion Code

```python
# Add your code here
```

#### Matrix Inversion Input

```
[Add your input format here]
```

#### Matrix Inversion Output

```
[Add your output format here]
```

---

## Solution of Non-Linear Equations

---

### Bisection Method

#### Bisection Theory
[Add your theory content here]

#### Bisection Code
```python
# Add your code here
````

#### Bisection Input

```
[Add your input format here]
```

#### Bisection Output

```
[Add your output format here]
```

---

### False Position Method

#### False Position Theory

[Add your theory content here]

#### False Position Code

```python
# Add your code here
```

#### False Position Input

```
[Add your input format here]
```

#### False Position Output

```
[Add your output format here]
```

---

### Newton Raphson Method

#### Newton Raphson Theory

[Add your theory content here]

#### Newton Raphson Code

```python
# Add your code here
```

#### Newton Raphson Input

```
[Add your input format here]
```

#### Newton Raphson Output

```
[Add your output format here]
```

---

### Secant Method

#### Secant Theory

[Add your theory content here]

#### Secant Code

```python
# Add your code here
```

#### Secant Input

```
[Add your input format here]
```

#### Secant Output

```
[Add your output format here]
```

---

## Differential Equation Solving

---

### Runge-Kutta 4th Order Method

#### Runge-Kutta Theory

[Add your theory content here]

#### Runge-Kutta Code

```python
# Add your code here
```

#### Runge-Kutta Input

```
[Add your input format here]
```

#### Runge-Kutta Output

```
[Add your output format here]
```

---

## Interpolation Methods

---

### Newton Forward Interpolation

#### Newton Forward Theory

[Add your theory content here]

#### Newton Forward Code

```python
# Add your code here
```

#### Newton Forward Input

```
[Add your input format here]
```

#### Newton Forward Output

```
[Add your output format here]
```

---

### Newton Backward Interpolation

#### Newton Backward Theory

[Add your theory content here]

#### Newton Backward Code

```python
# Add your code here
```

#### Newton Backward Input

```
[Add your input format here]
```

#### Newton Backward Output

```
[Add your output format here]
```

---

### Newton Divided Difference Interpolation

#### Newton Divided Difference Theory

[Add your theory content here]

#### Newton Divided Difference Code

```python
# Add your code here
```

#### Newton Divided Difference Input

```
[Add your input format here]
```

#### Newton Divided Difference Output

```
[Add your output format here]
```

---

## Numerical Differentiation

---

### Differentiation by Forward Interpolation

#### Differentiation Forward Theory

[Add your theory content here]

#### Differentiation Forward Code

```python
# Add your code here
```

#### Differentiation Forward Input

```
[Add your input format here]
```

#### Differentiation Forward Output

```
[Add your output format here]
```

---

### Differentiation by Backward Interpolation

#### Differentiation Backward Theory

[Add your theory content here]

#### Differentiation Backward Code

```python
# Add your code here
```

#### Differentiation Backward Input

```
[Add your input format here]
```

#### Differentiation Backward Output

```
[Add your output format here]
```

---

## Curve Fitting / Regression

---

### Linear Regression

#### Linear Regression Theory

[Add your theory content here]

#### Linear Regression Code

```python
# Add your code here
```

#### Linear Regression Input

```
[Add your input format here]
```

#### Linear Regression Output

```
[Add your output format here]
```

---

### Polynomial Regression

#### Polynomial Regression Theory

[Add your theory content here]

#### Polynomial Regression Code

```python
# Add your code here
```

#### Polynomial Regression Input

```
[Add your input format here]
```

#### Polynomial Regression Output

```
[Add your output format here]
```

---

### Transcendental Regression

#### Transcendental Regression Theory

[Add your theory content here]

#### Transcendental Regression Code

```python
# Add your code here
```

#### Transcendental Regression Input

```
[Add your input format here]
```

#### Transcendental Regression Output

```
[Add your output format here]
```

---

## Numerical Integration

---

### Simpson's 1/3 Rule

#### Simpson 1/3 Theory

```
Numerical integration is used to evaluate definite integrals when the analytical solution of an integral is either difficult or impossible to obtain. Simpson’s 1/3 Rule is one of the most widely used numerical integration techniques due to its simplicity and relatively high accuracy. In this method, the entire integration interval is divided into an even number of equal sub-intervals. The fundamental assumption of Simpson’s 1/3 Rule is that the function can be approximated by a second-degree polynomial (parabola) over each pair of consecutive sub-intervals.
Unlike the trapezoidal rule, which assumes linear variation of the function, Simpson’s 1/3 Rule assumes a smooth and continuous curvature of the function. As a result, it provides better accuracy, especially for functions that are reasonably smooth within the given limits.

Formula :
Let the lower and upper limits of integration be a and b respectively. The interval [a, b] is divided into n equal sub-intervals, where n must be an even number. 
step size, h = (b − a) / n.
The approximate value of the definite integral is given by:
∫a to b f(x) dx ≈ (h/3)[f(x0) + f(xn) + 4(f(x1)+f(x3)+…) + 2(f(x2)+f(x4)+…)]

Algorithm :
1. Read the lower limit a, upper limit b, and an even number of sub-intervals n. 
2. Calculate the step size h using h = (b − a) / n. 
3. Evaluate the function at the first and last points and add them.
4.Evaluate the function at all odd-indexed points and multiply each by 4. 
5. Evaluate the function at all even-indexed points (excluding boundaries) and multiply each by 2. 6. Add all the weighted function values. 
7. Multiply the total sum by h/3 to obtain the approximate value of the integral.

Working Principle :
Simpson’s 1/3 Rule works by fitting a parabolic curve through three equally spaced points of the function. By integrating this parabolic approximation instead of the original function, the area under the curve is estimated with improved precision. The use of different weighting factors for odd and even indexed points ensures that the curvature of the function is properly accounted for.

```

#### Simpson 1/3 Code

```cpp
#include<iostream>
#include<fstream>
#include<cmath>
using namespace std;

double f(double x){
    return x*x+1;
}

double simpsonOneThird(double a,double b,int n){
    double h=(b-a)/n;
    double sum=f(a)+f(b);
    for(int i=1;i<n;i++){
        double x=a+i*h;
        if(i%2==0) sum+=2*f(x);
        else sum+=4*f(x);
    }
    return (h/3)*sum;
}

int main(){
    ifstream fin("input.txt");
    ofstream fout("output_1_3.txt");
    double a,b;
    int n;
    int t=1;
    while(fin>>a>>b>>n){
        fout<<"Test case "<<t<<": a="<<a<<", b="<<b<<", n="<<n<<"\n";
        double result=simpsonOneThird(a,b,n);
        fout<<"Approximate integral="<<result<<"\n\n";
        t++;
    }
    fin.close();
    fout.close();
    return 0;
}


```

#### Simpson 1/3 Input

```
0 2 4
1 3 6
0 5 12

```

#### Simpson 1/3 Output

```
Test case 1: a=0, b=2, n=4
Approximate integral=4.66667

Test case 2: a=1, b=3, n=6
Approximate integral=10

Test case 3: a=0, b=5, n=12
Approximate integral=46.875

```

---

### Simpson's 3/8 Rule

#### Simpson 3/8 Theory

[Add your theory content here]

#### Simpson 3/8 Code

```cpp
# Add your code here
```

#### Simpson 3/8 Input

```
[Add your input format here]
```

#### Simpson 3/8 Output

```
[Add your output format here]
```


